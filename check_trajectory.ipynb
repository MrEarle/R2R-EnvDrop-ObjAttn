{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt-homes/kraken/mrearle/repos/R2R-EnvDrop-ObjAttn\n"
     ]
    }
   ],
   "source": [
    "%cd /home/mrearle/repos/R2R-EnvDrop-ObjAttn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "metadata_parser_path = '/home/mrearle/repos/R2R-EnvDrop-ObjAttn/metadata_parser'\n",
    "if metadata_parser_path not in sys.path:\n",
    "    sys.path.append(metadata_parser_path)\n",
    "\n",
    "mattersim_path = '/home/mrearle/datasets/Matterport3DSimulator/build'\n",
    "if mattersim_path not in sys.path:\n",
    "    sys.path.append(mattersim_path)\n",
    "    \n",
    "src_path = '/home/mrearle/repos/R2R-EnvDrop-ObjAttn/r2r_src'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_house_segmentations import HouseSegmentationFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Using RMSProp\n",
      "Using device: cuda\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11178MB, multi_processor_count=28)\n",
      "\n",
      "\n",
      "\tTraining model default in experiment default\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from param import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model args\n",
    "args.name = 'agent_bt_val'\n",
    "args.attn = 'soft'\n",
    "args.train = 'validlistener'\n",
    "args.angle_feat_size = 128\n",
    "args.accumulateGrad = True\n",
    "args.featdropout = 0.4\n",
    "args.subout = 'max'\n",
    "args.optim = 'rms'\n",
    "args.lr = 1e-4\n",
    "args.iters = 10\n",
    "args.maxAction = 35\n",
    "\n",
    "# Obj attn args\n",
    "base = False\n",
    "args.obj_attn_type = \"connection\"\n",
    "args.max_obj_number = 32\n",
    "args.obj_aux_task = not base\n",
    "args.obj_aux_task_weight = 0.1\n",
    "args.dataset = \"R2R\"\n",
    "args.include_objs = not base\n",
    "args.include_objs_lstm = False\n",
    "args.reduced_envs = True\n",
    "args.buffer_objs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(CANDIDATE_FEATURES='img_features/ResNet-152-candidate.tsv', IMAGENET_FEATURES='img_features/ResNet-152-imagenet.tsv', OBJECT_CLASS_FILE='/workspace1/mrearle/object_classes.json', OBJECT_FEATURES='/workspace1/mrearle/object_features_filtered.hdf5', TRAINVAL_VOCAB='tasks/R2R/data/trainval_vocab.txt', TRAIN_VOCAB='tasks/R2R/data/train_vocab.txt', accumulateGrad=True, accumulate_grad=False, aemb=64, alpha=0.5, angle_feat_size=128, attn='soft', aug=None, batchSize=64, beam=False, bidir=True, buffer_objs=False, candidate_mask=False, candidates=1, dataset='R2R', device=device(type='cuda'), dropout=0.5, encode='word', epsilon=0.1, experiment='default', fast_train=False, featdropout=0.4, feature_size=2048, features='imagenet', features_fast='img_features/ResNet-152-imagenet-fast.tsv', feedback='sample', gamma=0.9, ignoreid=-100, include_objs=True, include_objs_lstm=False, iters=10, listener=None, load=None, loadOptim=False, log_dir='snap/default/default', logging_vis=False, lr=0.0001, maxAction=35, maxDecode=120, maxInput=80, max_obj_number=32, ml_weight=0.05, name='agent_bt_val', normalize_loss='total', num_obj_classes=41, obj_attn_type='connection', obj_aux_task=True, obj_aux_task_weight=0.1, optim='rms', optimizer=<class 'torch.optim.rmsprop.RMSprop'>, param_search=False, proj=512, reduced_env_ids={'TbHJrupSAjP', 'pLe4wQe7qrG', 'HxpKQynjfin', 'XcA2TqTSSAj', '1LXtFkjw3qL', 'zsNo4HB9uLZ', 'cV4RVeZvu5T', 'PX4nDJXEHrG', 'EU6Fwq7SyZv', 'oLBMNvg9in8', 'r1Q1Z4BcV1o', 'Z6MFQCViBuw', 'QUCTc6BB5sX', '2azQ1b91cZZ', 'gZ6f7yhEvPG', '2n8kARJN3HM', 'EDJbREhghzL', '8WUmhLawc2A', '1pXnuDYAj8r', 'sT4fr6TAbpF', 'E9uDoFAP3SH', '82sE5b5pLXE', 'Uxmj2M2itWa', 'p5wJjkQkbXX', 'VLzqgDo317F', 'x8F5xyUWy9e', '8194nk5LbLH', 'X7HyMhZNoso', 'PuKPg4mmafe', 'JF19kD82Mey', 'pRbA3pwrgk9', 'VFuaQ6m2Qom'}, reduced_envs=True, rnn_dim=512, save_dir='default/default', self_train=False, speaker=None, sub_out='tanh', submit=False, subout='max', teacher='final', teacher_weight=1.0, train='validlistener', valid=False, views=36, weight_decay=0.0, wemb=256, zero_init=False)\n"
     ]
    }
   ],
   "source": [
    "from agent import Seq2SeqAgent\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from collections import OrderedDict\n",
    "from train import setup, read_vocab, Tokenizer, TRAIN_VOCAB, read_img_features, R2RBatch, Evaluation\n",
    "\n",
    "log_dir = args.log_dir\n",
    "FEATURE_FILE = \"/home/mrearle/storage/img_features/ResNet-152-imagenet.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2I is defaultdict True\n",
      "OLD_VOCAB_SIZE 991\n",
      "VOCAB_SIZE 992\n",
      "VOACB 991\n",
      "The feature size is 2048\n",
      "Loading navigation graphs for 21 scans\n",
      "R2RBatch loaded with 4895 instructions, using splits: train\n",
      "The feature size is 2048\n",
      "Loading navigation graphs for 11 scans\n",
      "R2RBatch loaded with 2349 instructions, using splits: val_unseen\n"
     ]
    }
   ],
   "source": [
    "setup()\n",
    "\n",
    "vocab = read_vocab(TRAIN_VOCAB)\n",
    "tok = Tokenizer(vocab=vocab, encoding_length=args.maxInput)\n",
    "\n",
    "feat_h5 = h5py.File(FEATURE_FILE, \"r\")\n",
    "obj_feat_h5 = h5py.File(args.OBJECT_FEATURES, \"r\")\n",
    "\n",
    "featurized_scans = set(feat_h5.keys())\n",
    "\n",
    "train_env = R2RBatch(\n",
    "    feature_store=feat_h5, object_feat_store=obj_feat_h5, batch_size=args.batchSize, splits=[\"train\"], tokenizer=tok\n",
    ")\n",
    "\n",
    "val_env_names = [\"val_unseen\"]\n",
    "\n",
    "val_envs = OrderedDict(\n",
    "        (\n",
    "            (\n",
    "                split,\n",
    "                (\n",
    "                    R2RBatch(\n",
    "                        feature_store=feat_h5,\n",
    "                        object_feat_store=obj_feat_h5,\n",
    "                        batch_size=args.batchSize,\n",
    "                        splits=[split],\n",
    "                        tokenizer=tok,\n",
    "                    ),\n",
    "                    Evaluation([split], featurized_scans, tok),\n",
    "                ),\n",
    "            )\n",
    "            for split in val_env_names\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bidir in EncoderLSTM\n",
      "ObjAttention: Using class ConnectionwiseObjectAttention\n",
      "Listener: Done Instantiating Model. Initializing Optimizers\n",
      "Listener: Done Instantiating Optimizers. Initializing Loss\n",
      "Listener: Done Instantiating Loss. Initializing Logs\n",
      "Listener: Flushed\n",
      "Listener: Done Instantiating Logs. Listener Initialized\n",
      "Loaded the listener model at iter 82500 from snap/agent-obj(32)-aux(0.1)-reduced/state_dict/best_val_unseen\n"
     ]
    }
   ],
   "source": [
    "agent = Seq2SeqAgent(train_env, \"\", tok, args.maxAction)\n",
    "\n",
    "agent_name = 'agent-obj(32)-aux(0.1)-reduced'\n",
    "\n",
    "args.load = f'snap/{agent_name}/state_dict/best_val_unseen'\n",
    "agent.results_path = f'results/{agent_name}.json'\n",
    "print(\n",
    "    \"Loaded the listener model at iter %d from %s\"\n",
    "    % (agent.load(args.load), args.load),\n",
    "    flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8caaa73a89a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"argmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0magent_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/R2R-EnvDrop-ObjAttn/r2r_src/agent.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, use_dropout, feedback, allow_cheat, iters)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeq2SeqAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/R2R-EnvDrop-ObjAttn/r2r_src/agent.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, iters, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Do a full round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instr_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mlooped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/R2R-EnvDrop-ObjAttn/r2r_src/agent.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, train_ml, train_rl, reset, speaker)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# Make action and get the new state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_equiv_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_a_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mperm_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_idx\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Perm the obs for the resu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/R2R-EnvDrop-ObjAttn/r2r_src/env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;31m# Full features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscanId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewpointId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;31m# Objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/R2R-EnvDrop-ObjAttn/r2r_src/env.py\u001b[0m in \u001b[0;36mmake_candidate\u001b[0;34m(self, feature, scanId, viewpointId, viewId)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mloc_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_heading\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbase_heading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mc_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"heading\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloc_heading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mangle_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"heading\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"elevation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0mc_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mc_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"normalized_heading\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/R2R-EnvDrop-ObjAttn/r2r_src/utils.py\u001b[0m in \u001b[0;36mangle_feature\u001b[0;34m(heading, elevation)\u001b[0m\n\u001b[1;32m    367\u001b[0m     return np.array(\n\u001b[1;32m    368\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melevation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melevation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle_feat_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m     )\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for env_name, (env, evaluator) in val_envs.items():\n",
    "    agent.logs = defaultdict(list)\n",
    "    agent.env = env\n",
    "\n",
    "    iters = None\n",
    "    agent.test(use_dropout=False, feedback=\"argmax\", iters=iters)\n",
    "agent_result = agent.write_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_path = 'tasks/R2R/data/R2R_val_unseen.json'\n",
    "base_agent_path = 'results/agent_base-reduced.json'\n",
    "obj_agent_path = 'results/agent-obj(32)-aux(0.1)-reduced.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nav_graphs(scans):\n",
    "    \"\"\"Load connectivity graph for each scan\"\"\"\n",
    "\n",
    "    def distance(pose1, pose2):\n",
    "        \"\"\"Euclidean distance between two graph poses\"\"\"\n",
    "        return (\n",
    "            (pose1[\"pose\"][3] - pose2[\"pose\"][3]) ** 2\n",
    "            + (pose1[\"pose\"][7] - pose2[\"pose\"][7]) ** 2\n",
    "            + (pose1[\"pose\"][11] - pose2[\"pose\"][11]) ** 2\n",
    "        ) ** 0.5\n",
    "\n",
    "    graphs = {}\n",
    "    for scan in scans:\n",
    "        with open(\"connectivity/%s_connectivity.json\" % scan) as f:\n",
    "            G = nx.Graph()\n",
    "            positions = {}\n",
    "            data = json.load(f)\n",
    "            for i, item in enumerate(data):\n",
    "                if item[\"included\"]:\n",
    "                    for j, conn in enumerate(item[\"unobstructed\"]):\n",
    "                        if conn and data[j][\"included\"]:\n",
    "                            positions[item[\"image_id\"]] = np.array([item[\"pose\"][3], item[\"pose\"][7], item[\"pose\"][11]])\n",
    "                            assert data[j][\"unobstructed\"][i], \"Graph should be undirected\"\n",
    "                            G.add_edge(\n",
    "                                item[\"image_id\"],\n",
    "                                data[j][\"image_id\"],\n",
    "                                weight=distance(item, data[j]),\n",
    "                            )\n",
    "            nx.set_node_attributes(G, values=positions, name=\"position\")\n",
    "            graphs[scan] = G\n",
    "    \n",
    "    img_id_to_graph = {}\n",
    "    for G in graphs.values():\n",
    "        for img_id in list(G.nodes()):\n",
    "            img_id_to_graph[img_id] = G\n",
    "    return graphs, img_id_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, img_id_to_graph = load_nav_graphs(featurized_scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(vp1, vp2):\n",
    "    \"\"\"Euclidean distance between two graph poses\"\"\"\n",
    "    pose1 = img_id_to_graph[vp1].nodes[vp1][\"position\"]\n",
    "    pose2 = img_id_to_graph[vp2].nodes[vp2][\"position\"]\n",
    "    return (\n",
    "        (pose1[0] - pose2[0]) ** 2\n",
    "        + (pose1[1] - pose2[1]) ** 2\n",
    "        + (pose1[2] - pose2[2]) ** 2\n",
    "    ) ** 0.5\n",
    "\n",
    "def success(vp1, vp2):\n",
    "    return distance(vp1, vp2) <= 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ground_truth_path) as f:\n",
    "    ground_truth = json.load(f)\n",
    "ground_truth = {v['path_id']: v['path'] for v in ground_truth}\n",
    "\n",
    "with open(base_agent_path) as f:\n",
    "    base_agent = json.load(f)\n",
    "base_agent = {v['instr_id']: v['trajectory'] for v in base_agent}\n",
    "\n",
    "with open(obj_agent_path) as f:\n",
    "    obj_agent = json.load(f)\n",
    "obj_agent = {v['instr_id']: v['trajectory'] for v in obj_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_cases = []\n",
    "fail_cases = []\n",
    "both_succs = []\n",
    "both_fails = []\n",
    "for instr_id in base_agent:\n",
    "    path_id, _ = instr_id.split('_')\n",
    "\n",
    "    base_agent_success = success(base_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "    obj_agent_success = success(obj_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "\n",
    "    if not base_agent_success and obj_agent_success:\n",
    "        succ_cases.append(instr_id)\n",
    "    elif not obj_agent_success and base_agent_success:\n",
    "        fail_cases.append(instr_id)\n",
    "    elif base_agent_success and obj_agent_success:\n",
    "        both_succs.append(instr_id)\n",
    "    elif not base_agent_success and not obj_agent_success:\n",
    "        both_fails.append(instr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 235, 558, 1344)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(succ_cases), len(fail_cases), len(both_succs), len(both_fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mrearle/repos/compute_conv_feats/splitted_instructions_val_unseen.json', 'r') as f:\n",
    "    obj_split_instruction = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_obj = { 'success': [], 'fail': [] }\n",
    "less_obj = { 'success': [], 'fail': [] }\n",
    "many_obj_base = { 'success': [], 'fail': [] }\n",
    "less_obj_base = { 'success': [], 'fail': [] }\n",
    "\n",
    "\n",
    "for instr_id in base_agent:\n",
    "    path_id, _ = instr_id.split('_')\n",
    "\n",
    "    path_type = 'many_obj' if instr_id in obj_split_instruction['many_objs'] else 'less_obj'\n",
    "\n",
    "    base_agent_success = success(base_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "    obj_agent_success = success(obj_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "\n",
    "    if path_type == 'many_obj':\n",
    "        many_obj['success' if obj_agent_success else 'fail'].append(instr_id)\n",
    "    else:\n",
    "        less_obj['success' if obj_agent_success else 'fail'].append(instr_id)\n",
    "\n",
    "    \n",
    "    if path_type == 'many_obj':\n",
    "        many_obj_base['success' if base_agent_success else 'fail'].append(instr_id)\n",
    "    else:\n",
    "        less_obj_base['success' if base_agent_success else 'fail'].append(instr_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj Agent\n",
      "389 950 381 629\n",
      "Many obj SR: 0.2905153099327857\n",
      "Less obj SR: 0.37722772277227723\n"
     ]
    }
   ],
   "source": [
    "print('Obj Agent')\n",
    "print(len(many_obj['success']), len(many_obj['fail']), len(less_obj['success']), len(less_obj['fail']))\n",
    "print('Many obj SR:', len(many_obj['success']) / (len(many_obj['success']) + len(many_obj['fail'])))\n",
    "print('Less obj SR:', len(less_obj['success']) / (len(less_obj['success']) + len(less_obj['fail'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Agent\n",
      "408 931 385 625\n",
      "Many obj SR: 0.30470500373412995\n",
      "Less obj SR: 0.3811881188118812\n"
     ]
    }
   ],
   "source": [
    "print('Base Agent')\n",
    "print(len(many_obj_base['success']), len(many_obj_base['fail']), len(less_obj_base['success']), len(less_obj_base['fail']))\n",
    "print('Many obj SR:', len(many_obj_base['success']) / (len(many_obj_base['success']) + len(many_obj_base['fail'])))\n",
    "print('Less obj SR:', len(less_obj_base['success']) / (len(less_obj_base['success']) + len(less_obj_base['fail'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c64bab987688411ecf7daeb0d26ce66b9c22149654c3c666032ea50efbbbd43"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 ('r2r')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
