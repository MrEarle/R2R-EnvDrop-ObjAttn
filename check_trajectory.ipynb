{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt-homes/kraken/mrearle/repos/R2R-EnvDrop-ObjAttn\n"
     ]
    }
   ],
   "source": [
    "%cd /home/mrearle/repos/R2R-EnvDrop-ObjAttn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "metadata_parser_path = '/home/mrearle/repos/R2R-EnvDrop-ObjAttn/metadata_parser'\n",
    "if metadata_parser_path not in sys.path:\n",
    "    sys.path.append(metadata_parser_path)\n",
    "\n",
    "mattersim_path = '/home/mrearle/datasets/Matterport3DSimulator/build'\n",
    "if mattersim_path not in sys.path:\n",
    "    sys.path.append(mattersim_path)\n",
    "    \n",
    "src_path = '/home/mrearle/repos/R2R-EnvDrop-ObjAttn/r2r_src'\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_house_segmentations import HouseSegmentationFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and run agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Using RMSProp\n",
      "Using device: cuda\n",
      "_CudaDeviceProperties(name='GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11178MB, multi_processor_count=28)\n",
      "\n",
      "\n",
      "\tTraining model default in experiment default\n",
      "\n",
      "\n",
      "Namespace(CANDIDATE_FEATURES='img_features/ResNet-152-candidate.tsv', IMAGENET_FEATURES='img_features/ResNet-152-imagenet.tsv', OBJECT_CLASS_FILE='/workspace1/mrearle/object_classes.json', OBJECT_FEATURES='/workspace1/mrearle/object_features_filtered.hdf5', TRAINVAL_VOCAB='tasks/R2R/data/trainval_vocab.txt', TRAIN_VOCAB='tasks/R2R/data/train_vocab.txt', accumulate_grad=False, aemb=64, alpha=0.5, angle_feat_size=4, attn='soft', aug=None, batchSize=64, beam=False, bidir=True, buffer_objs=False, candidate_mask=False, candidates=1, dataset='R2R', device=device(type='cuda'), dropout=0.5, encode='word', epsilon=0.1, experiment='default', fast_train=False, featdropout=0.3, feature_size=2048, features='imagenet', features_fast='img_features/ResNet-152-imagenet-fast.tsv', feedback='sample', gamma=0.9, ignoreid=-100, include_objs=False, include_objs_lstm=False, iters=100000, listener=None, load=None, loadOptim=False, log_dir='snap/default/default', logging_vis=False, lr=0.0001, maxAction=20, maxDecode=120, maxInput=80, max_obj_number=20, ml_weight=0.05, name='default', normalize_loss='total', num_obj_classes=41, obj_attn_type='connection', obj_aux_task=False, obj_aux_task_weight=0.1, obj_label_task=False, obj_label_task_weight=0.1, optim='rms', optimizer=<class 'torch.optim.rmsprop.RMSprop'>, param_search=False, proj=512, reduced_env_ids={'Uxmj2M2itWa', 'Z6MFQCViBuw', 'PuKPg4mmafe', 'PX4nDJXEHrG', 'QUCTc6BB5sX', 'r1Q1Z4BcV1o', 'p5wJjkQkbXX', 'VLzqgDo317F', '1pXnuDYAj8r', 'E9uDoFAP3SH', 'cV4RVeZvu5T', 'pRbA3pwrgk9', 'pLe4wQe7qrG', 'EDJbREhghzL', 'HxpKQynjfin', 'zsNo4HB9uLZ', '1LXtFkjw3qL', 'oLBMNvg9in8', 'VFuaQ6m2Qom', '82sE5b5pLXE', 'gZ6f7yhEvPG', 'EU6Fwq7SyZv', 'X7HyMhZNoso', '8194nk5LbLH', 'x8F5xyUWy9e', '2n8kARJN3HM', '8WUmhLawc2A', 'JF19kD82Mey', '2azQ1b91cZZ', 'TbHJrupSAjP', 'sT4fr6TAbpF', 'XcA2TqTSSAj'}, reduced_envs=False, rnn_dim=512, save_dir='default/default', self_train=False, speaker=None, sub_out='tanh', submit=False, teacher='final', teacher_weight=1.0, train='speaker', valid=False, views=36, weight_decay=0.0, wemb=256, zero_init=False)\n"
     ]
    }
   ],
   "source": [
    "from visualization_v2.agent_utils import load_args, args, load_envs, setup_agent as _setup_agent\n",
    "import os\n",
    "\n",
    "def setup_agent(\n",
    "    base_name: str,\n",
    "    max_obj_number: int = 20,\n",
    "    obj_aux_task: bool = True,\n",
    "    include_objs: bool = True,\n",
    "    reduced_envs: bool = True,\n",
    "    dataset: str = \"R2R\",\n",
    "):\n",
    "    print(\"Parsing args\")\n",
    "    load_args(\n",
    "        max_obj_number=max_obj_number,\n",
    "        obj_aux_task=obj_aux_task,\n",
    "        include_objs=include_objs,\n",
    "        reduced_envs=reduced_envs,\n",
    "        dataset=dataset,\n",
    "    )\n",
    "\n",
    "    print(\"Loading envs\")\n",
    "    train_env, val_envs, tok = load_envs()\n",
    "\n",
    "    experiment = []\n",
    "    if args.dataset.upper() != \"R2R\":\n",
    "        experiment.append(args.dataset)\n",
    "    if args.max_obj_number != 20:\n",
    "        experiment.append(f\"obj({args.max_obj_number})\")\n",
    "    if args.obj_aux_task:\n",
    "        experiment.append(f\"aux({args.obj_aux_task_weight})\")\n",
    "    if args.reduced_envs:\n",
    "        experiment.append(f\"reduced\")\n",
    "\n",
    "    args.experiment = \"_\".join(experiment) or \"default\"\n",
    "    print(base_name, args.experiment)\n",
    "    args.save_dir = os.path.join(base_name, args.experiment, \"__\")\n",
    "    load = f\"snap/{base_name}/{args.experiment}/state_dict/best_val_unseen\"\n",
    "\n",
    "    agent, obj_attns, view_attns = _setup_agent(train_env, tok, load)\n",
    "\n",
    "    agent.results_path = f\"results/{base_name}/{args.experiment}.json\"\n",
    "\n",
    "    return agent, val_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "from importlib import reload\n",
    "import visualization_v2.agent_utils as agent_utils\n",
    "reload(agent_utils)\n",
    "setup_and_run_agent = agent_utils.setup_and_run_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing args\n",
      "Namespace(CANDIDATE_FEATURES='img_features/ResNet-152-candidate.tsv', IMAGENET_FEATURES='img_features/ResNet-152-imagenet.tsv', OBJECT_CLASS_FILE='/workspace1/mrearle/object_classes.json', OBJECT_FEATURES='/workspace1/mrearle/object_features_filtered.hdf5', TRAINVAL_VOCAB='tasks/R2R/data/trainval_vocab.txt', TRAIN_VOCAB='tasks/R2R/data/train_vocab.txt', accumulate_grad=False, aemb=64, alpha=0.5, angle_feat_size=128, attn='soft', aug=None, batchSize=64, beam=False, bidir=True, buffer_objs=False, candidate_mask=False, candidates=1, dataset='R2R', device=device(type='cuda'), dropout=0.5, encode='word', epsilon=0.1, experiment='reduced', fast_train=False, featdropout=0.3, feature_size=2048, features='imagenet', features_fast='img_features/ResNet-152-imagenet-fast.tsv', feedback='sample', gamma=0.9, ignoreid=-100, include_objs=False, include_objs_lstm=False, iters=100000, listener=None, load='/home/mrearle/repos/R2R-EnvDrop-ObjAttn/snap/agent_base-reduced/state_dict/best_val_unseen', loadOptim=False, log_dir='snap/base/reduced', logging_vis=False, lr=0.0001, maxAction=35, maxDecode=120, maxInput=80, max_obj_number=20, ml_weight=0.05, name='base', normalize_loss='total', num_obj_classes=41, obj_attn_type='connection', obj_aux_task=False, obj_aux_task_weight=0.1, obj_label_task=False, obj_label_task_weight=0.1, optim='rms', optimizer=<class 'torch.optim.rmsprop.RMSprop'>, param_search=False, proj=512, reduced_env_ids={'QUCTc6BB5sX', 'EDJbREhghzL', 'pLe4wQe7qrG', 'PX4nDJXEHrG', 'E9uDoFAP3SH', 'cV4RVeZvu5T', 'gZ6f7yhEvPG', 'X7HyMhZNoso', 'sT4fr6TAbpF', '1pXnuDYAj8r', '2n8kARJN3HM', 'Uxmj2M2itWa', 'p5wJjkQkbXX', 'zsNo4HB9uLZ', 'Z6MFQCViBuw', '8WUmhLawc2A', 'VLzqgDo317F', 'oLBMNvg9in8', 'x8F5xyUWy9e', 'HxpKQynjfin', 'JF19kD82Mey', 'PuKPg4mmafe', 'VFuaQ6m2Qom', '2azQ1b91cZZ', 'r1Q1Z4BcV1o', 'pRbA3pwrgk9', 'XcA2TqTSSAj', '8194nk5LbLH', 'EU6Fwq7SyZv', '82sE5b5pLXE', 'TbHJrupSAjP', '1LXtFkjw3qL'}, reduced_envs=True, rnn_dim=512, save_dir='base/reduced', self_train=False, speaker=None, sub_out='max', submit=False, teacher='final', teacher_weight=1.0, train='validlistener', valid=False, views=36, weight_decay=0.0, wemb=256, zero_init=False)\n",
      "Setup agent\n",
      "W2I is defaultdict True\n",
      "OLD_VOCAB_SIZE 991\n",
      "VOCAB_SIZE 992\n",
      "VOACB 991\n",
      "The feature size is 2048\n",
      "Using dataset tasks/R2R/data/R2R_train.json for split train (arg: R2R)\n",
      "Loading navigation graphs for 21 scans\n",
      "R2RBatch loaded with 4895 instructions, using splits: train\n",
      "The feature size is 2048\n",
      "Using dataset tasks/R2R/data/R2R_val_unseen.json for split val_unseen (arg: R2R)\n",
      "Loading navigation graphs for 11 scans\n",
      "R2RBatch loaded with 2349 instructions, using splits: val_unseen\n",
      "Using dataset tasks/R2R/data/R2R_val_unseen.json for split val_unseen (arg: R2R)\n",
      "The feature size is 2048\n",
      "Using dataset tasks/R2R/data/R2R_val_seen.json for split val_seen (arg: R2R)\n",
      "Loading navigation graphs for 20 scans\n",
      "R2RBatch loaded with 345 instructions, using splits: val_seen\n",
      "Using dataset tasks/R2R/data/R2R_val_seen.json for split val_seen (arg: R2R)\n",
      "The feature size is 2048\n",
      "Using dataset tasks/R2R/data/R2R_train.json for split train (arg: R2R)\n",
      "Loading navigation graphs for 21 scans\n",
      "R2RBatch loaded with 4895 instructions, using splits: train\n",
      "Using dataset tasks/R2R/data/R2R_train.json for split train (arg: R2R)\n",
      "Using Bidir in EncoderLSTM\n",
      "Listener: Done Instantiating Model. Initializing Optimizers\n",
      "Listener: Done Instantiating Optimizers. Initializing Loss\n",
      "Listener: Done Instantiating Loss. Initializing Logs\n",
      "Listener: Flushed\n",
      "Listener: Done Instantiating Logs. Listener Initialized\n",
      "Loading from /home/mrearle/repos/R2R-EnvDrop-ObjAttn/snap/agent_base-reduced/state_dict/best_val_unseen\n",
      "Loaded the listener model at iter 59000 from /home/mrearle/repos/R2R-EnvDrop-ObjAttn/snap/agent_base-reduced/state_dict/best_val_unseen\n",
      "None\n",
      "Env name: val_unseen, nav_error: 6.6810, oracle_error: 4.4240, steps: 24.2112, lengths: 9.2796, success_rate: 0.3942, oracle_rate: 0.4687, spl: 0.3632\n",
      "Env name: val_seen, nav_error: 6.0501, oracle_error: 4.0458, steps: 25.6290, lengths: 10.9942, success_rate: 0.4551, oracle_rate: 0.5478, spl: 0.4381\n",
      "Env name: train, nav_error: 0.0347, oracle_error: 0.0283, steps: 25.5685, lengths: 10.5497, success_rate: 0.9998, oracle_rate: 1.0000, spl: 0.9965\n",
      "Loading envs\n",
      "W2I is defaultdict True\n",
      "OLD_VOCAB_SIZE 991\n",
      "VOCAB_SIZE 992\n",
      "VOACB 991\n",
      "The feature size is 2048\n",
      "Using dataset tasks/R2R/data/R2R_train.json for split train (arg: R2R)\n",
      "Loading navigation graphs for 21 scans\n",
      "R2RBatch loaded with 4895 instructions, using splits: train\n",
      "The feature size is 2048\n",
      "Using dataset tasks/R2R/data/R2R_val_unseen.json for split val_unseen (arg: R2R)\n",
      "Loading navigation graphs for 11 scans\n",
      "R2RBatch loaded with 2349 instructions, using splits: val_unseen\n",
      "Using dataset tasks/R2R/data/R2R_val_unseen.json for split val_unseen (arg: R2R)\n",
      "Run agent\n"
     ]
    }
   ],
   "source": [
    "agent, _, _ = setup_and_run_agent(\n",
    "    base_name=\"base\",\n",
    "    max_obj_number=20,\n",
    "    obj_aux_task = False,\n",
    "    include_objs = False,\n",
    "    reduced_envs = True,\n",
    "    dataset = \"R2R\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97b84fddce33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "args.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_envs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-010dee764eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_envs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_envs' is not defined"
     ]
    }
   ],
   "source": [
    "for env_name, (env, evaluator) in val_envs.items():\n",
    "    agent.logs = defaultdict(list)\n",
    "    agent.env = env\n",
    "\n",
    "    iters = None\n",
    "    agent.test(use_dropout=False, feedback=\"argmax\", iters=iters)\n",
    "\n",
    "result = agent.get_results()\n",
    "score_summary, _ = evaluator.score(result)\n",
    "loss_str = \"Env name: %s\" % env_name\n",
    "for metric, val in score_summary.items():\n",
    "    loss_str += \", %s: %.4f\" % (metric, val)\n",
    "print(loss_str, flush=True)\n",
    "# log_dir = \"results/submit/%s\" % args.save_dir\n",
    "# json.dump(\n",
    "#     result,\n",
    "#     open(os.path.join(log_dir, \"submit_%s.json\" % env_name), \"w\"),\n",
    "#     sort_keys=True,\n",
    "#     indent=4,\n",
    "#     separators=(\",\", \": \"),\n",
    "# )\n",
    "# print(evaluator.score(agent.get_results())[0])\n",
    "# agent_result = agent.write_results()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_unseen']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_path = 'semantically_richer_instructions/R2R_craft_val_unseen.json'\n",
    "base_agent_path = 'results/base/craft_reduced/best_val_unseen.json'\n",
    "obj_agent_path = 'results/obj/craft_obj(32)_aux(0.1)_reduced/best_val_unseen.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SPLITS = {\n",
    "    \"train\": [\n",
    "        \"Uxmj2M2itWa\",\n",
    "        \"82sE5b5pLXE\",\n",
    "        \"2n8kARJN3HM\",\n",
    "        \"1pXnuDYAj8r\",\n",
    "        \"VLzqgDo317F\",\n",
    "        \"p5wJjkQkbXX\",\n",
    "        \"r1Q1Z4BcV1o\",\n",
    "        \"HxpKQynjfin\",\n",
    "        \"PuKPg4mmafe\",\n",
    "        \"cV4RVeZvu5T\",\n",
    "        \"PX4nDJXEHrG\",\n",
    "        \"VFuaQ6m2Qom\",\n",
    "        \"JF19kD82Mey\",\n",
    "        \"sT4fr6TAbpF\",\n",
    "        \"E9uDoFAP3SH\",\n",
    "        \"XcA2TqTSSAj\",\n",
    "        \"8WUmhLawc2A\",\n",
    "        \"EDJbREhghzL\",\n",
    "        \"1LXtFkjw3qL\",\n",
    "        \"pRbA3pwrgk9\",\n",
    "        \"gZ6f7yhEvPG\",\n",
    "    ],\n",
    "    \"val_seen\": [\n",
    "        \"Uxmj2M2itWa\",\n",
    "        \"82sE5b5pLXE\",\n",
    "        \"2n8kARJN3HM\",\n",
    "        \"1pXnuDYAj8r\",\n",
    "        \"VLzqgDo317F\",\n",
    "        \"p5wJjkQkbXX\",\n",
    "        \"r1Q1Z4BcV1o\",\n",
    "        \"PuKPg4mmafe\",\n",
    "        \"cV4RVeZvu5T\",\n",
    "        \"PX4nDJXEHrG\",\n",
    "        \"VFuaQ6m2Qom\",\n",
    "        \"JF19kD82Mey\",\n",
    "        \"sT4fr6TAbpF\",\n",
    "        \"E9uDoFAP3SH\",\n",
    "        \"XcA2TqTSSAj\",\n",
    "        \"8WUmhLawc2A\",\n",
    "        \"1LXtFkjw3qL\",\n",
    "        \"EDJbREhghzL\",\n",
    "        \"pRbA3pwrgk9\",\n",
    "        \"gZ6f7yhEvPG\",\n",
    "    ],\n",
    "    \"val_unseen\": [\n",
    "        \"2azQ1b91cZZ\",\n",
    "        \"QUCTc6BB5sX\",\n",
    "        \"zsNo4HB9uLZ\",\n",
    "        \"oLBMNvg9in8\",\n",
    "        \"8194nk5LbLH\",\n",
    "        \"EU6Fwq7SyZv\",\n",
    "        \"x8F5xyUWy9e\",\n",
    "        \"Z6MFQCViBuw\",\n",
    "        \"X7HyMhZNoso\",\n",
    "        \"pLe4wQe7qrG\",\n",
    "        \"TbHJrupSAjP\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "scans = {x for split in SMALL_SPLITS.values() for x in split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nav_graphs(scans):\n",
    "    \"\"\"Load connectivity graph for each scan\"\"\"\n",
    "\n",
    "    def distance(pose1, pose2):\n",
    "        \"\"\"Euclidean distance between two graph poses\"\"\"\n",
    "        return (\n",
    "            (pose1[\"pose\"][3] - pose2[\"pose\"][3]) ** 2\n",
    "            + (pose1[\"pose\"][7] - pose2[\"pose\"][7]) ** 2\n",
    "            + (pose1[\"pose\"][11] - pose2[\"pose\"][11]) ** 2\n",
    "        ) ** 0.5\n",
    "\n",
    "    graphs = {}\n",
    "    for scan in scans:\n",
    "        with open(\"connectivity/%s_connectivity.json\" % scan) as f:\n",
    "            G = nx.Graph()\n",
    "            positions = {}\n",
    "            data = json.load(f)\n",
    "            for i, item in enumerate(data):\n",
    "                if item[\"included\"]:\n",
    "                    for j, conn in enumerate(item[\"unobstructed\"]):\n",
    "                        if conn and data[j][\"included\"]:\n",
    "                            positions[item[\"image_id\"]] = np.array([item[\"pose\"][3], item[\"pose\"][7], item[\"pose\"][11]])\n",
    "                            assert data[j][\"unobstructed\"][i], \"Graph should be undirected\"\n",
    "                            G.add_edge(\n",
    "                                item[\"image_id\"],\n",
    "                                data[j][\"image_id\"],\n",
    "                                weight=distance(item, data[j]),\n",
    "                            )\n",
    "            nx.set_node_attributes(G, values=positions, name=\"position\")\n",
    "            graphs[scan] = G\n",
    "    \n",
    "    img_id_to_scan = {}\n",
    "    for scan, G in graphs.items():\n",
    "        for img_id in list(G.nodes()):\n",
    "            img_id_to_scan[img_id] = scan\n",
    "    return graphs, img_id_to_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, img_id_to_scan = load_nav_graphs(scans)\n",
    "ERROR_MARGIN = 3.0\n",
    "distances = {}\n",
    "for scan, G in graphs.items():  # compute all shortest paths\n",
    "    distances[scan] = dict(nx.all_pairs_dijkstra_path_length(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(vp1, vp2):\n",
    "    scan = img_id_to_scan[vp1]\n",
    "    pos1 = graphs[scan].nodes[vp1]['position']\n",
    "    pos2 = graphs[scan].nodes[vp2]['position']\n",
    "    dist = distances[scan][vp1][vp2]\n",
    "    # dist = np.linalg.norm(pos1 - pos2)\n",
    "    if dist <= 3.0:\n",
    "        return True\n",
    "    else:\n",
    "        # print(f\"{vp1},{vp2},{dist}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ground_truth_path) as f:\n",
    "    ground_truth = json.load(f)\n",
    "ground_truth = {v['path_id']: v['path'] for v in ground_truth}\n",
    "\n",
    "with open(base_agent_path) as f:\n",
    "    base_agent = json.load(f)\n",
    "base_agent = {v['instr_id']: v['trajectory'] for v in base_agent}\n",
    "\n",
    "with open(obj_agent_path) as f:\n",
    "    obj_agent = json.load(f)\n",
    "obj_agent = {v['instr_id']: v['trajectory'] for v in obj_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "succs = {'base': set(), 'obj': set()}\n",
    "fails = {'base': set(), 'obj': set()}\n",
    "\n",
    "for instr_id in base_agent:\n",
    "    path_id, _ = instr_id.split('_')\n",
    "\n",
    "    base_agent_success = success(base_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "    obj_agent_success = success(obj_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "\n",
    "    base_dict = succs if base_agent_success else fails\n",
    "    obj_dict = succs if obj_agent_success else fails\n",
    "\n",
    "    base_dict['base'].add(instr_id)\n",
    "    obj_dict['obj'].add(instr_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'254_0' in succs['obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successes:\n",
      "\tBase: 389\n",
      "\tObj: 410\n",
      "Fails:\n",
      "\tBase: 394\n",
      "\tObj: 373\n",
      "Success Rate:\n",
      "\tBase: 0.49680715197956576\n",
      "\tObj: 0.5236270753512133\n"
     ]
    }
   ],
   "source": [
    "print(f\"Successes:\\n\\tBase: {len(succs['base'])}\\n\\tObj: {len(succs['obj'])}\")\n",
    "print(f\"Fails:\\n\\tBase: {len(fails['base'])}\\n\\tObj: {len(fails['obj'])}\")\n",
    "print(f\"Success Rate:\\n\\tBase: {len(succs['base']) / len(base_agent)}\\n\\tObj: {len(succs['obj']) / len(obj_agent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj succeded where base failed: 100\n",
      "Obj failed where base succeded: 79\n",
      "Both succeded: 310\n",
      "Both failed: 294\n"
     ]
    }
   ],
   "source": [
    "obj_better = succs['obj'].intersection(fails['base'])\n",
    "obj_worse = fails['obj'].intersection(succs['base'])\n",
    "bot_succ = succs['obj'].intersection(succs['base'])\n",
    "bot_fail = fails['obj'].intersection(fails['base'])\n",
    "print(f'Obj succeded where base failed: {len(obj_better)}')\n",
    "print(f'Obj failed where base succeded: {len(obj_worse)}')\n",
    "print(f'Both succeded: {len(bot_succ)}')\n",
    "print(f'Both failed: {len(bot_fail)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49680715197956576"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(79 +  310) / (100 + 310 + 79 + 294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "def compact_traj(traj):\n",
    "    res = []\n",
    "    for view in traj:\n",
    "        if view not in res:\n",
    "            res.append(view)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bot_fail)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n",
      "ground truth       base               obj         \n",
      "273092f839e945eb   273092f839e945eb   273092f839e945eb\n",
      "7ef2af7db85e4b9b   7ef2af7db85e4b9b   7ef2af7db85e4b9b\n",
      "76e1ef125ea2458c   76e1ef125ea2458c   76e1ef125ea2458c\n",
      "7976fb70011347e5                      c644381db1ea4bdb\n",
      "af1005e4b2804e39                      af1005e4b2804e39\n",
      "f320ae084f3a447d                      f320ae084f3a447d\n",
      "e8ae2f7717b54c6d                      e8ae2f7717b54c6d\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "instr = '4976_0'\n",
    "print(instr in succs['obj'], instr in succs['base'])\n",
    "gt = compact_traj(ground_truth[int(instr.split('_')[0])])\n",
    "base = compact_traj([x[0] for x in base_agent[instr]])\n",
    "obj = compact_traj([x[0] for x in obj_agent[instr]])\n",
    "\n",
    "width = 16\n",
    "gt = [x[:width] for x in gt]\n",
    "base = [x[:width] for x in base]\n",
    "obj = [x[:width] for x in obj]\n",
    "\n",
    "print(f\"{'ground truth': <16} {'  base': <16} {'    obj': <16}\")\n",
    "print(*['   '.join(x) for x in zip_longest(gt, base, obj, fillvalue=' '*width)], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[img_id_to_scan['0a9f30bd318e40de89f71e4bf6987358']]['ac3dc08c7a2646b991fda42ccc42bc47']['0cf8775a4e474671bc23337c84da1540']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mrearle/repos/compute_conv_feats/splitted_instructions_val_unseen.json', 'r') as f:\n",
    "    obj_split_instruction = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_obj = { 'success': [], 'fail': [] }\n",
    "less_obj = { 'success': [], 'fail': [] }\n",
    "many_obj_base = { 'success': [], 'fail': [] }\n",
    "less_obj_base = { 'success': [], 'fail': [] }\n",
    "\n",
    "\n",
    "for instr_id in base_agent:\n",
    "    path_id, _ = instr_id.split('_')\n",
    "\n",
    "    path_type = 'many_obj' if instr_id in obj_split_instruction['many_objs'] else 'less_obj'\n",
    "\n",
    "    base_agent_success = success(base_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "    obj_agent_success = success(obj_agent[instr_id][-1][0], ground_truth[int(path_id)][-1])\n",
    "\n",
    "    if path_type == 'many_obj':\n",
    "        many_obj['success' if obj_agent_success else 'fail'].append(instr_id)\n",
    "    else:\n",
    "        less_obj['success' if obj_agent_success else 'fail'].append(instr_id)\n",
    "\n",
    "    \n",
    "    if path_type == 'many_obj':\n",
    "        many_obj_base['success' if base_agent_success else 'fail'].append(instr_id)\n",
    "    else:\n",
    "        less_obj_base['success' if base_agent_success else 'fail'].append(instr_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj Agent\n",
      "200 243 210 130\n",
      "Many obj SR: 0.45146726862302483\n",
      "Less obj SR: 0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "print('Obj Agent')\n",
    "print(len(many_obj['success']), len(many_obj['fail']), len(less_obj['success']), len(less_obj['fail']))\n",
    "print('Many obj SR:', len(many_obj['success']) / (len(many_obj['success']) + len(many_obj['fail'])))\n",
    "print('Less obj SR:', len(less_obj['success']) / (len(less_obj['success']) + len(less_obj['fail'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Agent\n",
      "195 248 194 146\n",
      "Many obj SR: 0.4401805869074492\n",
      "Less obj SR: 0.5705882352941176\n"
     ]
    }
   ],
   "source": [
    "print('Base Agent')\n",
    "print(len(many_obj_base['success']), len(many_obj_base['fail']), len(less_obj_base['success']), len(less_obj_base['fail']))\n",
    "print('Many obj SR:', len(many_obj_base['success']) / (len(many_obj_base['success']) + len(many_obj_base['fail'])))\n",
    "print('Less obj SR:', len(less_obj_base['success']) / (len(less_obj_base['success']) + len(less_obj_base['fail'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c64bab987688411ecf7daeb0d26ce66b9c22149654c3c666032ea50efbbbd43"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
